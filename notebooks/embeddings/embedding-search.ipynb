{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Based Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will leverage embedding spaces & nearest neighbor search to recommend news articles. We can take features of the news articles, convert them into embeddings, and then utilize similarity search to find the most similar embedding vectors to a given article's embedding, thereby finding similar and relevant news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/c40kpr1n23gdq2_k3l47l1n40000gn/T/ipykernel_10026/1207345874.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a [Kaggle Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset). Download the Kaggle dataset, and save it in the same directory as this notebook as `News_Category_Dataset_v3.json.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('News_Category_Dataset_v3.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of columns, and we probably won't need most of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"headline\", \"short_description\", \"category\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>COMEDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>PARENTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "\n",
       "                                   short_description   category  \n",
       "0  Health experts said it is too early to predict...  U.S. NEWS  \n",
       "1  He was subdued by passengers and crew when he ...  U.S. NEWS  \n",
       "2  \"Until you have a dog you don't understand wha...     COMEDY  \n",
       "3  \"Accidentally put grown-up toothpaste on my to...  PARENTING  \n",
       "4  Amy Cooper accused investment firm Franklin Te...  U.S. NEWS  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is colossal. Let's work with a small sample of the data for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data with regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\&\", \" and \", text)\n",
    "    text = re.sub(r\"\\|\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # Eliminate all punctuation\n",
    "    text = re.sub(r\"[^\\w\\d\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"headline\"] = df[\"headline\"].apply(clean_text)\n",
    "df[\"short_description\"] = df[\"short_description\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: 10 Women Photographers Who Are Changing The Way We See The World\n",
      "Category: ARTS & CULTURE\n",
      "About: Women have been fundamental to the art of photography since well there were photographs\n",
      "\n",
      "Headline: Jared Leto Nearly Sacrificed His Eyebrows For The Sake Of Acting\n",
      "Category: STYLE\n",
      "About: Could the world handle a browless Leto face\n",
      "\n",
      "Headline: How Do You Measure Commitment To The Iran Nuclear Deal\n",
      "Category: WORLD NEWS\n",
      "About: While Irans targets are technical and verifiable the targets for US compliance are not\n",
      "\n",
      "Headline: All Saints Day 2015 Dates Facts And Traditions\n",
      "Category: RELIGION\n",
      "About: On this day Catholics honor all those who have entered heaven\n",
      "\n",
      "Headline: Trumps Week Of Errors Exaggerations And FlatOut Falsehoods\n",
      "Category: POLITICS\n",
      "About: Donald Trump says he is a truthful man Maybe truthful to a fault he boasted last week at a North Carolina rally where\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in df.head(5).iterrows():\n",
    "    print(\"Headline:\", row[\"headline\"])\n",
    "    print(\"Category:\", row[\"category\"])\n",
    "    print(\"About:\", row[\"short_description\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features of the news articles should we use when trying to recommend similar news articles? A combinination of the headline and description is a good start. News articles with a semantically similar headline + description are probably relevant to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new column that appends headline and short_description. \n",
    "# this will be the input to the model\n",
    "df[\"text\"] = df[\"headline\"] + \" \" + df[\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_embedding(text: str, model: str = EMBEDDING_MODEL):\n",
    "    # print(text)\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00433637 -0.01465408  0.00101204 ... -0.00239996 -0.00236265\n",
      " -0.00170826]\n"
     ]
    }
   ],
   "source": [
    "h1 = \"Tech Giant Announces Groundbreaking AI Advancements in Automation\"\n",
    "h2 = \"Leading Tech Corporation Unveils Revolutionary Developments in AI Technology\"\n",
    "\n",
    "print(np.array(get_embedding(h1)) - np.array(get_embedding(h2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a cache of embeddings to avoid recomputing - saves time and money\n",
    "# Cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# Set path to embedding cache\n",
    "embedding_cache_path = \"recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# Load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    # Return embedding of given string, using a cache to avoid recomputing.\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: 10 Women Photographers Who Are Changing The Way We See The World Women have been fundamental to the art of photography since well there were photographs\n",
      "\n",
      "Example embedding: [-0.00557529553771019, 6.832373765064403e-05, 0.00066228280775249, -0.013964998535811901, 0.02160860039293766, 0.015690160915255547, -0.042839426547288895, 0.004737899638712406, 0.007284717168658972, -0.03258919343352318]...\n"
     ]
    }
   ],
   "source": [
    "# as an example, take the first description from the dataset\n",
    "example_string = df[\"text\"].values[0]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_from_embeddings(query_embedding: list, embeddings: list) -> list:\n",
    "    \"\"\"Return distances between query and each embedding in embeddings.\"\"\"\n",
    "    def cosine_similarity(embedding1, embedding2):\n",
    "        return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "\n",
    "    return [cosine_similarity(query_embedding, embedding) for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_of_closest_matches_from_distances(distances: list) -> list:\n",
    "    \"\"\"Return indices of n_matches closest embeddings to query.\"\"\"\n",
    "    # distances = distances_from_embeddings(query, embeddings)\n",
    "    # return sorted(range(len(distances)), key=lambda i: distances[i])[:n_matches]\n",
    "    return (sorted(range(len(distances)), key=lambda i: distances[i]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    # get distances between the source embedding and other embeddings\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings)\n",
    "    \n",
    "    indices_of_nearest_neighbors = indices_of_closest_matches_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k articles\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for a given article, we can generate recommendations for it. Try this with different `article_no` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: 10 Women Photographers Who Are Changing The Way We See The World\n",
      "Description: Women have been fundamental to the art of photography since well there were photographs\n"
     ]
    }
   ],
   "source": [
    "article_no = 0\n",
    "\n",
    "print(\"Headline:\", df.iloc[article_no][\"headline\"])\n",
    "print(\"Description:\", df.iloc[article_no][\"short_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 Women Photographers Who Are Changing The Way We See The World Women have been fundamental to the art of photography since well there were photographs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"].values[article_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --- Recommendation #1 (nearest neighbor 1 of 10) ---\n",
      "        String: International Festival Of Arts And Ideas Kicks Off In New Haven PHOTOS The two week festival was founded in 1996 differentiating itself from the other established art fairs with its interdisciplinary\n",
      "        Distance: 0.780\n",
      "\n",
      "        --- Recommendation #2 (nearest neighbor 2 of 10) ---\n",
      "        String: Helena Bonham Carter Vogue UK Cover Is Porcelain Perfection PHOTOS Want more Be sure to check out HuffPost Style on Twitter Facebook Tumblr Pinterest and Instagram at HuffPostStyle Shot\n",
      "        Distance: 0.776\n",
      "\n",
      "        --- Recommendation #3 (nearest neighbor 3 of 10) ---\n",
      "        String: Cameron Diazs Beauty Evolution From Teen Model To Screen Siren PHOTOS As 39yearold Diaz celebrates the release of What To Expect When Youre Expecting on May 18th were taking a look back\n",
      "        Distance: 0.776\n",
      "\n",
      "        --- Recommendation #4 (nearest neighbor 4 of 10) ---\n",
      "        String: 6 Ways Change Will Transform You Change is liberating and healing and plain unavoidable The more we welcome it the more profoundly positive its impact We know we can survive and overcome\n",
      "        Distance: 0.776\n",
      "\n",
      "        --- Recommendation #5 (nearest neighbor 5 of 10) ---\n",
      "        String: Madeleine Albright Spends Inauguration Day With Americas Future Leaders The future is most definitely female\n",
      "        Distance: 0.775\n",
      "\n",
      "        --- Recommendation #6 (nearest neighbor 6 of 10) ---\n",
      "        String: NASA Images Of The Week Jan 20 PHOTOS From a sun explosion to an enormous star death to a mysterious dusty cluster five million years old NASAs best photos\n",
      "        Distance: 0.772\n",
      "\n",
      "        --- Recommendation #7 (nearest neighbor 7 of 10) ---\n",
      "        String: The Creative Lone Wolf The growing Creative Economy and the democratization of production is fostering a large generation of lone wolf professionals competing fiercely for a place in the sun and their fifteen minutes of fame\n",
      "        Distance: 0.770\n",
      "\n",
      "        --- Recommendation #8 (nearest neighbor 8 of 10) ---\n",
      "        String: The Weeks Best Style Moments Kelly Rowland Tina Turner And Christy Teigen PHOTOS Tina Turner made her way to China for the first time ever which is a total surprise to take in Armanis One Night Only\n",
      "        Distance: 0.767\n",
      "\n",
      "        --- Recommendation #9 (nearest neighbor 9 of 10) ---\n",
      "        String: J Crew x CFDAVogue Fashion Fund Collaboration Is On Its Way PHOTOS Below three Voguettes have styled themselves in some J Crew x CFDAVogue Fashion Fund pieces Head to Voguecom to see\n",
      "        Distance: 0.765\n",
      "\n",
      "        --- Recommendation #10 (nearest neighbor 10 of 10) ---\n",
      "        String: Kids Toys More Gendered Than Ever Megan Perrymans 5yearold daughter was browsing toys in a store She picked up a toy recorder and her expression quickly\n",
      "        Distance: 0.765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 240,\n",
       " 238,\n",
       " 24,\n",
       " 110,\n",
       " 225,\n",
       " 60,\n",
       " 53,\n",
       " 246,\n",
       " 162,\n",
       " 18,\n",
       " 52,\n",
       " 127,\n",
       " 196,\n",
       " 210,\n",
       " 147,\n",
       " 101,\n",
       " 149,\n",
       " 93,\n",
       " 58,\n",
       " 249,\n",
       " 37,\n",
       " 223,\n",
       " 165,\n",
       " 218,\n",
       " 142,\n",
       " 183,\n",
       " 19,\n",
       " 173,\n",
       " 108,\n",
       " 178,\n",
       " 145,\n",
       " 205,\n",
       " 136,\n",
       " 212,\n",
       " 8,\n",
       " 167,\n",
       " 245,\n",
       " 80,\n",
       " 16,\n",
       " 13,\n",
       " 124,\n",
       " 116,\n",
       " 59,\n",
       " 111,\n",
       " 234,\n",
       " 164,\n",
       " 221,\n",
       " 115,\n",
       " 48,\n",
       " 180,\n",
       " 199,\n",
       " 163,\n",
       " 122,\n",
       " 227,\n",
       " 202,\n",
       " 179,\n",
       " 228,\n",
       " 76,\n",
       " 144,\n",
       " 74,\n",
       " 241,\n",
       " 233,\n",
       " 208,\n",
       " 159,\n",
       " 140,\n",
       " 187,\n",
       " 230,\n",
       " 229,\n",
       " 146,\n",
       " 102,\n",
       " 6,\n",
       " 43,\n",
       " 23,\n",
       " 189,\n",
       " 132,\n",
       " 50,\n",
       " 9,\n",
       " 158,\n",
       " 3,\n",
       " 170,\n",
       " 54,\n",
       " 209,\n",
       " 70,\n",
       " 40,\n",
       " 112,\n",
       " 155,\n",
       " 200,\n",
       " 192,\n",
       " 17,\n",
       " 243,\n",
       " 28,\n",
       " 175,\n",
       " 169,\n",
       " 26,\n",
       " 36,\n",
       " 134,\n",
       " 126,\n",
       " 117,\n",
       " 119,\n",
       " 123,\n",
       " 104,\n",
       " 91,\n",
       " 201,\n",
       " 133,\n",
       " 7,\n",
       " 195,\n",
       " 22,\n",
       " 81,\n",
       " 141,\n",
       " 83,\n",
       " 77,\n",
       " 100,\n",
       " 185,\n",
       " 27,\n",
       " 130,\n",
       " 148,\n",
       " 12,\n",
       " 143,\n",
       " 32,\n",
       " 216,\n",
       " 242,\n",
       " 128,\n",
       " 171,\n",
       " 57,\n",
       " 186,\n",
       " 98,\n",
       " 51,\n",
       " 177,\n",
       " 151,\n",
       " 191,\n",
       " 94,\n",
       " 247,\n",
       " 15,\n",
       " 42,\n",
       " 75,\n",
       " 217,\n",
       " 92,\n",
       " 89,\n",
       " 95,\n",
       " 156,\n",
       " 34,\n",
       " 56,\n",
       " 105,\n",
       " 99,\n",
       " 79,\n",
       " 86,\n",
       " 68,\n",
       " 226,\n",
       " 135,\n",
       " 84,\n",
       " 139,\n",
       " 33,\n",
       " 5,\n",
       " 29,\n",
       " 213,\n",
       " 2,\n",
       " 193,\n",
       " 150,\n",
       " 25,\n",
       " 239,\n",
       " 47,\n",
       " 184,\n",
       " 152,\n",
       " 63,\n",
       " 85,\n",
       " 232,\n",
       " 55,\n",
       " 97,\n",
       " 35,\n",
       " 90,\n",
       " 194,\n",
       " 203,\n",
       " 118,\n",
       " 38,\n",
       " 198,\n",
       " 67,\n",
       " 153,\n",
       " 44,\n",
       " 231,\n",
       " 215,\n",
       " 20,\n",
       " 190,\n",
       " 125,\n",
       " 154,\n",
       " 131,\n",
       " 161,\n",
       " 220,\n",
       " 10,\n",
       " 114,\n",
       " 113,\n",
       " 61,\n",
       " 46,\n",
       " 214,\n",
       " 157,\n",
       " 174,\n",
       " 78,\n",
       " 71,\n",
       " 4,\n",
       " 82,\n",
       " 224,\n",
       " 1,\n",
       " 106,\n",
       " 222,\n",
       " 172,\n",
       " 137,\n",
       " 204,\n",
       " 66,\n",
       " 62,\n",
       " 72,\n",
       " 168,\n",
       " 206,\n",
       " 11,\n",
       " 88,\n",
       " 244,\n",
       " 120,\n",
       " 49,\n",
       " 45,\n",
       " 176,\n",
       " 64,\n",
       " 160,\n",
       " 138,\n",
       " 121,\n",
       " 21,\n",
       " 248,\n",
       " 166,\n",
       " 107,\n",
       " 69,\n",
       " 87,\n",
       " 96,\n",
       " 103,\n",
       " 207,\n",
       " 219,\n",
       " 39,\n",
       " 41,\n",
       " 129,\n",
       " 14,\n",
       " 181,\n",
       " 236,\n",
       " 109,\n",
       " 235,\n",
       " 197,\n",
       " 73,\n",
       " 188,\n",
       " 65,\n",
       " 31,\n",
       " 182,\n",
       " 211,\n",
       " 30,\n",
       " 237]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = df[\"text\"].values\n",
    "\n",
    "print_recommendations_from_strings(descriptions, article_no, k_nearest_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations *should* make sense. If they don't, you must have gotten a really unlucky sample of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've reached the end, here are some additional things you can spend your time doing in groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the more Data Science / ML oriented people:\n",
    "- Try to do this with completely different datasets! What about taking Amazon Reviews and doing a review recommendation system? Think about how your preprocessing will differ (your reviews dataset may include lots of numbers you'd want to remove or substitute, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the more Computer Science / Data Structures & Algo oriented:\n",
    "- K-Nearest Neighbors - the search algorithm we used - is pretty inefficient. Approximate Nearest Neighbors, or ANN, is significantly quicker, but sacrifices some accuracy. Try to do the recommendation search, but with an ANN heuristic like Hierarchical Navigable Small World (HNSW). Many vector databases use HNSW, so this should be an interesting and relevant exercise that'll provide you some background for similarity search next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other questions to maybe ponder, and get answered:\n",
    "- What if we didn't use embeddings? What if we used [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (Term Frequency * Inverse Document Frequency) vectorization instead and did similarity search based on that? \n",
    "- What if we use another distance function, like euclidean distance, or dot product instead of cosine similarity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
